{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abdd4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b930a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ds    EMP       IND       Prod Rigs Wells    Store    WTI  Brent\n",
      "622 2023-11-01  119.8  110.4381  13281.094  498   817  441.838  77.69  82.94\n",
      "623 2023-12-01  121.1  109.2864  13307.958  501   858  426.491   71.9  77.63\n",
      "624 2024-01-01  122.1  108.5309  12553.566  499   784  427.857  74.15  80.12\n",
      "625 2024-02-01  121.9  108.0537   13102.08  500   838  447.929  77.25  83.48\n",
      "626 2024-03-01  122.1  109.0561  13170.783  507   828  447.206  81.28  85.41\n",
      "627 2024-04-01  121.8  105.2515  13248.629  508   937  463.842  85.35  89.94\n",
      "628 2024-05-01  122.7  103.1317  13201.128  497   807  454.548  80.02  81.75\n",
      "629 2024-06-01  123.2  103.7599  13239.855  486   818  440.151  79.77  82.25\n",
      "630 2024-07-01  123.0  103.4599  13191.927  479   955  427.207   81.8  85.15\n",
      "631 2024-08-01  121.9  103.7464  13363.545  483   878   417.35  76.68  80.36\n",
      "632 2024-09-01  122.5  105.0522  13184.702  486   787  415.933  70.24  74.02\n",
      "633 2024-10-01  122.5  103.3379  13450.094  481   931  423.629  71.99  75.63\n",
      "634 2024-11-01  122.9   99.8826  13352.046  478   759  421.308  69.95  74.35\n",
      "635 2024-12-01  123.0   99.6103  13437.831  483   765  413.734  70.12  73.86\n",
      "636 2025-01-01  123.1   98.5717  13140.518  478   758  418.782  75.74  79.27\n",
      "637 2025-02-01  122.4   99.1446  13239.885  484   769  429.786  71.53  75.44\n",
      "638 2025-03-01  122.3   99.9934  13488.269  486   771  431.688  68.24  72.73\n",
      "639 2025-04-01  122.6   98.2472  13442.833  475   770  438.666  63.54  68.13\n",
      "640 2025-05-01  122.8    95.689  13398.032  462   745  435.018  62.17  64.45\n",
      "641 2025-06-01  122.3       NaN        NaN  NaN   NaN      NaN  68.17  71.44\n"
     ]
    }
   ],
   "source": [
    "# Pull FRED Data\n",
    "FRED_KEY = '02b2c2d2bbf883773e270d39679071c9'\n",
    "FREDurl = 'https://api.stlouisfed.org/fred/series/observations'\n",
    "\n",
    "\n",
    "\n",
    "param1 = {\n",
    "    'series_id': 'CES1021100001',\n",
    "    'api_key': FRED_KEY,\n",
    "    'file_type': 'json'}\n",
    "\n",
    "response = requests.get(FREDurl, params=param1)\n",
    "data = response.json()\n",
    "observations = data['observations']\n",
    "df1 = pd.DataFrame(observations)\n",
    "df1 = df1.rename(columns={\"date\": \"ds\",\"value\": \"EMP\"})\n",
    "df1 = df1[['ds', 'EMP']]\n",
    "\n",
    "param2 = {\n",
    "    'series_id': 'IPN213111S',\n",
    "    'api_key': FRED_KEY,\n",
    "    'file_type': 'json'}\n",
    "\n",
    "response = requests.get(FREDurl, params=param2)\n",
    "data = response.json()\n",
    "observations = data['observations']\n",
    "df2 = pd.DataFrame(observations)\n",
    "df2 = df2.rename(columns={\"date\": \"ds\",\"value\": \"IND\"})\n",
    "df2 = df2[['ds', 'IND']]\n",
    "\n",
    "\n",
    "# Pull EIA Data\n",
    "EIA_KEY = 'S5kBDUycUiKkFCG6uxywpfYtq7IzU7AAhOgoUU4y'\n",
    "\n",
    "\n",
    "# Initialize parameters\n",
    "Date = \"2010-01-01\"\n",
    "End = None\n",
    "# API endpoints \n",
    "# EIA endpoints\n",
    "\n",
    "\n",
    " \n",
    "urlPrice = 'https://api.eia.gov/v2/petroleum/pri/spt/data/'   \n",
    "totalurl = 'https://api.eia.gov/v2/total-energy/data/'\n",
    "\n",
    "# Parameters\n",
    "\n",
    "WTI = {\n",
    "    \"api_key\": EIA_KEY, # API key\n",
    "    \"frequency\": \"monthly\", # Frequency of data\n",
    "    \"data[0]\": \"value\",  \n",
    "    \"facets[series][0]\": \"RWTC\",  # Series ID\n",
    "    \"start\": Date , # Start date\n",
    "    \"end\": End, # End date\n",
    "    \"sort[0][column]\": \"period\",\n",
    "    \"sort[0][direction]\": \"desc\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 500\n",
    "}\n",
    "\n",
    "Brent = {\n",
    "    \"api_key\": EIA_KEY, # API key\n",
    "    \"frequency\": \"monthly\", # Frequency of data\n",
    "    \"data[0]\": \"value\",  \n",
    "    \"facets[series][0]\": \"RBRTE\",  # Series ID\n",
    "    \"start\": Date , # Start date\n",
    "    \"end\": End, # End date\n",
    "    \"sort[0][column]\": \"period\",\n",
    "    \"sort[0][direction]\": \"desc\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 500\n",
    "}\n",
    "\n",
    "Prod = {\n",
    "    \"api_key\": EIA_KEY, # API key\n",
    "    \"frequency\": \"monthly\", # Frequency of data\n",
    "    \"data[0]\": \"value\",  \n",
    "    \"facets[msn][0]\": \"PAPRPUS\",  # Series ID\n",
    "    \"start\": Date , # Start date\n",
    "    \"end\": End, # End date\n",
    "    \"sort[0][column]\": \"period\",\n",
    "    \"sort[0][direction]\": \"desc\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 500\n",
    "}\n",
    "\n",
    "Rigs = {\n",
    "    \"api_key\": EIA_KEY, # API key\n",
    "    \"frequency\": \"monthly\", # Frequency of data\n",
    "    \"data[0]\": \"value\",  \n",
    "    \"facets[msn][0]\": \"PANRPUS\",  # Series ID\n",
    "    \"start\": Date , # Start date\n",
    "    \"end\": End, # End date\n",
    "    \"sort[0][column]\": \"period\",\n",
    "    \"sort[0][direction]\": \"desc\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 500\n",
    "}\n",
    "\n",
    "Wells = {\n",
    "    \"api_key\": EIA_KEY, # API key\n",
    "    \"frequency\": \"monthly\", # Frequency of data\n",
    "    \"data[0]\": \"value\",  \n",
    "    \"facets[msn][0]\": \"PATWPUS\",  # Series ID\n",
    "    \"start\": Date , # Start date\n",
    "    \"end\": End, # End date\n",
    "    \"sort[0][column]\": \"period\",\n",
    "    \"sort[0][direction]\": \"desc\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 500\n",
    "}\n",
    "\n",
    "Storage = {\n",
    "    \"api_key\": EIA_KEY, # API key\n",
    "    \"frequency\": \"monthly\", # Frequency of data\n",
    "    \"data[0]\": \"value\",  \n",
    "    \"facets[msn][0]\": \"COSXPUS\",  # Series ID\n",
    "    \"start\": Date , # Start date\n",
    "    \"end\": End, # End date\n",
    "    \"sort[0][column]\": \"period\",\n",
    "    \"sort[0][direction]\": \"desc\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 500\n",
    "}\n",
    "\n",
    "response2 = requests.get(urlPrice, params=WTI)\n",
    "data2 = response2.json()\n",
    "df6 = pd.DataFrame(data2['response']['data'])\n",
    "df6 = df6[['period', 'value']]\n",
    "df6.rename(columns={'value': 'WTI'}, inplace=True)\n",
    "df6.rename(columns={'period': 'ds'}, inplace=True)\n",
    "\n",
    "response2 = requests.get(urlPrice, params=Brent)\n",
    "data2 = response2.json()\n",
    "df8 = pd.DataFrame(data2['response']['data'])\n",
    "df8 = df8[['period', 'value']]\n",
    "df8.rename(columns={'value': 'Brent'}, inplace=True)\n",
    "df8.rename(columns={'period': 'ds'}, inplace=True)\n",
    "\n",
    "\n",
    "response2 = requests.get(totalurl, params=Prod)\n",
    "data2 = response2.json()\n",
    "df3 = pd.DataFrame(data2['response']['data'])\n",
    "df3 = df3[['period', 'value']]\n",
    "df3.rename(columns={'value': 'Prod'}, inplace=True)\n",
    "df3.rename(columns={'period': 'ds'}, inplace=True)\n",
    "\n",
    "response2 = requests.get(totalurl, params=Rigs)\n",
    "data2 = response2.json()\n",
    "df4 = pd.DataFrame(data2['response']['data'])\n",
    "df4 = df4[['period', 'value']]\n",
    "df4.rename(columns={'value': 'Rigs'}, inplace=True)\n",
    "df4.rename(columns={'period': 'ds'}, inplace=True)\n",
    "\n",
    "response2 = requests.get(totalurl, params=Wells)\n",
    "data2 = response2.json()\n",
    "df5 = pd.DataFrame(data2['response']['data'])\n",
    "df5 = df5[['period', 'value']]\n",
    "df5.rename(columns={'value': 'Wells'}, inplace=True)\n",
    "df5.rename(columns={'period': 'ds'}, inplace=True)\n",
    "\n",
    "response2 = requests.get(totalurl, params=Storage)\n",
    "data2 = response2.json()\n",
    "df7 = pd.DataFrame(data2['response']['data'])\n",
    "df7 = df7[['period', 'value']]\n",
    "df7.rename(columns={'value': 'Store'}, inplace=True)\n",
    "df7.rename(columns={'period': 'ds'}, inplace=True)\n",
    "\n",
    "\n",
    "for df in [df1, df2, df3, df4, df5, df6, df7, df8]:\n",
    "    df['ds'] = pd.to_datetime(df['ds']).dt.to_period('M').dt.to_timestamp()\n",
    "df_merged = df1\n",
    "df_merged = pd.merge(df_merged, df2, on='ds', how='outer')\n",
    "df_merged = pd.merge(df_merged, df3, on='ds', how='outer')\n",
    "df_merged = pd.merge(df_merged, df4, on='ds', how='outer')\n",
    "df_merged = pd.merge(df_merged, df5, on='ds', how='outer')\n",
    "df_merged = pd.merge(df_merged, df7, on='ds', how='outer')\n",
    "df_merged = pd.merge(df_merged, df6, on='ds', how='outer')\n",
    "df_merged = pd.merge(df_merged, df8, on='ds', how='outer')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df_merged.tail(20))\n",
    "\n",
    "df_merged.to_pickle(\"Production.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3001d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ds    EMP       IND       Prod  Rigs Wells    Store        WTI  \\\n",
      "623 2023-12-01  121.1  109.2864  13307.958   501   858  426.491       71.9   \n",
      "624 2024-01-01  122.1  108.5309  12553.566   499   784  427.857      74.15   \n",
      "625 2024-02-01  121.9  108.0537   13102.08   500   838  447.929      77.25   \n",
      "626 2024-03-01  122.1  109.0561  13170.783   507   828  447.206      81.28   \n",
      "627 2024-04-01  121.8  105.2515  13248.629   508   937  463.842      85.35   \n",
      "628 2024-05-01  122.7  103.1317  13201.128   497   807  454.548      80.02   \n",
      "629 2024-06-01  123.2  103.7599  13239.855   486   818  440.151      79.77   \n",
      "630 2024-07-01  123.0  103.4599  13191.927   479   955  427.207       81.8   \n",
      "631 2024-08-01  121.9  103.7464  13363.545   483   878   417.35      76.68   \n",
      "632 2024-09-01  122.5  105.0522  13184.702   486   787  415.933      70.24   \n",
      "633 2024-10-01  122.5  103.3379  13450.094   481   931  423.629      71.99   \n",
      "634 2024-11-01  122.9   99.8826  13352.046   478   759  421.308      69.95   \n",
      "635 2024-12-01  123.0   99.6103  13437.831   483   765  413.734      70.12   \n",
      "636 2025-01-01  123.1   98.5717  13140.518   478   758  418.782      75.74   \n",
      "637 2025-02-01  122.4   99.1446  13239.885   484   769  429.786      71.53   \n",
      "638 2025-03-01  122.3   99.9934  13488.269   486   771  431.688      68.24   \n",
      "639 2025-04-01  122.6   98.2472  13442.833   475   770  438.666      63.54   \n",
      "640 2025-05-01  122.8    95.689  13398.032   462   745  435.018      62.17   \n",
      "641 2025-06-01  122.3       NaN        NaN   NaN   NaN      NaN      68.17   \n",
      "642 2025-07-01   None      None       None  None  None     None  68.232104   \n",
      "\n",
      "         Brent  \n",
      "623      77.63  \n",
      "624      80.12  \n",
      "625      83.48  \n",
      "626      85.41  \n",
      "627      89.94  \n",
      "628      81.75  \n",
      "629      82.25  \n",
      "630      85.15  \n",
      "631      80.36  \n",
      "632      74.02  \n",
      "633      75.63  \n",
      "634      74.35  \n",
      "635      73.86  \n",
      "636      79.27  \n",
      "637      75.44  \n",
      "638      72.73  \n",
      "639      68.13  \n",
      "640      64.45  \n",
      "641      71.44  \n",
      "642  70.264738  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Approximate current month pricing data\n",
    "df = pd.read_pickle(\"Production.pkl\")\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "# === Step 1: Get current month start ===\n",
    "last_reported_month = df['ds'].max()\n",
    "next_month_start = last_reported_month + relativedelta(months=1)\n",
    "\n",
    "\n",
    "# === Step 2: Check if row exists for current month ===\n",
    "if next_month_start not in df['ds'].values:\n",
    "    \n",
    "    # === Step 3: Get 30-day average prices from yfinance ===\n",
    "    today = datetime.today()\n",
    "    start_date = today - timedelta(days=30)\n",
    "\n",
    "    wti = yf.download(\"CL=F\", start=start_date, end=today)['Close'].dropna()\n",
    "    wti_avg = wti.mean().item()\n",
    "\n",
    "    brent = yf.download('BZ=F', start=start_date, end=today)['Close'].dropna()\n",
    "    brent_avg = brent.mean().item()\n",
    "\n",
    "    # === Step 4: Create new row ===\n",
    "    new_row = {\n",
    "        'ds': next_month_start,\n",
    "        'WTI': wti_avg,\n",
    "        'Brent': brent_avg,\n",
    "        # Fill other columns with NaN\n",
    "        'EMP': None,\n",
    "        'IND': None,\n",
    "        'Prod': None,\n",
    "        'Store': None,\n",
    "        'Rigs': None,\n",
    "        'Wells': None,\n",
    "    }\n",
    "\n",
    "    # === Step 5: Append to DataFrame ===\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    " \n",
    "\n",
    "\n",
    "df.to_pickle(\"Production1.pkl\")\n",
    "\n",
    "print(df.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7905c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ds    EMP       IND       Prod  Rigs Wells    Store        WTI  \\\n",
      "623 2023-12-01  121.1  109.2864  14295.958   501   858  426.491       71.9   \n",
      "624 2024-01-01  122.1  108.5309  12976.566   499   784  427.857      74.15   \n",
      "625 2024-02-01  121.9  108.0537  13799.080   500   838  447.929      77.25   \n",
      "626 2024-03-01  122.1  109.0561  14052.783   507   828  447.206      81.28   \n",
      "627 2024-04-01  121.8  105.2515  14057.629   508   937  463.842      85.35   \n",
      "628 2024-05-01  122.7  103.1317  13584.128   497   807  454.548      80.02   \n",
      "629 2024-06-01  123.2  103.7599  13997.855   486   818  440.151      79.77   \n",
      "630 2024-07-01  123.0  103.4599  13296.927   479   955  427.207       81.8   \n",
      "631 2024-08-01  121.9  103.7464  14238.545   483   878   417.35      76.68   \n",
      "632 2024-09-01  122.5  105.0522  13527.702   486   787  415.933      70.24   \n",
      "633 2024-10-01  122.5  103.3379  14022.094   481   931  423.629      71.99   \n",
      "634 2024-11-01  122.9   99.8826  14385.046   478   759  421.308      69.95   \n",
      "635 2024-12-01  123.0   99.6103  13877.831   483   765  413.734      70.12   \n",
      "636 2025-01-01  123.1   98.5717  13229.518   478   758  418.782      75.74   \n",
      "637 2025-02-01  122.4   99.1446  14008.885   484   769  429.786      71.53   \n",
      "638 2025-03-01  122.3   99.9934  14261.269   486   771  431.688      68.24   \n",
      "639 2025-04-01  122.6   98.2472  14107.833   475   770  438.666      63.54   \n",
      "640 2025-05-01  122.8    95.689        NaN   462   745  435.018      62.17   \n",
      "641 2025-06-01  122.3       NaN        NaN   NaN   NaN      NaN      68.17   \n",
      "642 2025-07-01   None      None        NaN  None  None     None  68.232104   \n",
      "\n",
      "         Brent  \n",
      "623      77.63  \n",
      "624      80.12  \n",
      "625      83.48  \n",
      "626      85.41  \n",
      "627      89.94  \n",
      "628      81.75  \n",
      "629      82.25  \n",
      "630      85.15  \n",
      "631      80.36  \n",
      "632      74.02  \n",
      "633      75.63  \n",
      "634      74.35  \n",
      "635      73.86  \n",
      "636      79.27  \n",
      "637      75.44  \n",
      "638      72.73  \n",
      "639      68.13  \n",
      "640      64.45  \n",
      "641      71.44  \n",
      "642  70.264738  \n"
     ]
    }
   ],
   "source": [
    "# Adjust for EIA reporting error\n",
    "EIA_KEY = 'S5kBDUycUiKkFCG6uxywpfYtq7IzU7AAhOgoUU4y'\n",
    "\n",
    "\n",
    "# Initialize parameters\n",
    "Date = \"2010-01-01\"\n",
    "End = None\n",
    "# API endpoints \n",
    "# EIA endpoints\n",
    "\n",
    "sndurl = 'https://api.eia.gov/v2/petroleum/sum/snd/data/'\n",
    "\n",
    "adjust = {\n",
    "    \"api_key\": EIA_KEY, # API key\n",
    "    \"frequency\": \"monthly\", # Frequency of data\n",
    "    \"data[0]\": \"value\",  \n",
    "    \"facets[series][0]\": \"MCRUA_NUS_2\",  # Series ID\n",
    "    \"start\": Date , # Start date\n",
    "    \"end\": End, # End date\n",
    "    \"sort[0][column]\": \"period\",\n",
    "    \"sort[0][direction]\": \"desc\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 500\n",
    "}\n",
    "response2 = requests.get(sndurl, params=adjust)\n",
    "data2 = response2.json()\n",
    "df3 = pd.DataFrame(data2['response']['data'])\n",
    "df3 = df3[['period', 'value']]\n",
    "df3.rename(columns={'value': 'Adjust'}, inplace=True)\n",
    "df3.rename(columns={'period': 'ds'}, inplace=True)\n",
    "\n",
    "df = pd.read_pickle(\"Production1.pkl\")\n",
    "\n",
    "# Ensure 'ds' is datetime in both DataFrames\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df3['ds'] = pd.to_datetime(df3['ds'])\n",
    "\n",
    "# Merge adjustment values into df\n",
    "df = pd.merge(df, df3[['ds', 'Adjust']], on='ds', how='left')\n",
    "\n",
    "# Add adjustment to Demand (make sure both columns are numeric)\n",
    "df['Prod'] = pd.to_numeric(df['Prod'], errors='coerce') + pd.to_numeric(df['Adjust'], errors='coerce')\n",
    "\n",
    "# Drop the Adjust column if no longer needed\n",
    "df.drop(columns=['Adjust'], inplace=True)\n",
    "\n",
    " \n",
    "url = 'https://api.eia.gov/v2/petroleum/sum/snd/data/'\n",
    "\n",
    "# Parameters\n",
    "\n",
    "Transfer = {\n",
    "    \"api_key\": EIA_KEY, # API key\n",
    "    \"frequency\": \"monthly\", # Frequency of data\n",
    "    \"data[0]\": \"value\",  \n",
    "    \"facets[series][0]\": \"M_EPC0_TVP_NUS_MBBLD\",  # Series ID\n",
    "    \"start\": Date , # Start date\n",
    "    \"end\": End, # End date\n",
    "    \"sort[0][column]\": \"period\",\n",
    "    \"sort[0][direction]\": \"desc\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 500\n",
    "}\n",
    "\n",
    "\n",
    "response2 = requests.get(url, params=Transfer)\n",
    "data2 = response2.json()\n",
    "df6 = pd.DataFrame(data2['response']['data'])\n",
    "df6 = df6[['period', 'value']]\n",
    "df6.rename(columns={'value': 'Transfers'}, inplace=True)\n",
    "df6.rename(columns={'period': 'ds'}, inplace=True)\n",
    "df6['ds'] = pd.to_datetime(df6['ds'])\n",
    "\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df6['ds'] = pd.to_datetime(df6['ds'])\n",
    "\n",
    "# Merge adjustment values into df\n",
    "df = pd.merge(df, df6[['ds', 'Transfers']], on='ds', how='left')\n",
    "\n",
    "# Add adjustment to Demand (make sure both columns are numeric)\n",
    "df['Prod'] = pd.to_numeric(df['Prod'], errors='coerce') + pd.to_numeric(df['Transfers'], errors='coerce')\n",
    "\n",
    "# Drop the Adjust column if no longer needed\n",
    "df.drop(columns=['Transfers'], inplace=True)\n",
    "\n",
    "# View result\n",
    "print(df.tail(20))\n",
    "\n",
    "df.to_pickle(\"Production1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808552c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hold-Out Backtest Error Metrics ===\n",
      "MAE  (Mean Absolute Error):      1.68\n",
      "RMSE (Root Mean Squared Error): 2.12\n",
      "MAPE (Mean Absolute % Error):   1.37%\n",
      "\n",
      "=== Final df with historical + forecasted values ===\n",
      "        ds        EMP\n",
      "2024-12-01 123.000000\n",
      "2025-01-01 123.100000\n",
      "2025-02-01 122.400000\n",
      "2025-03-01 122.300000\n",
      "2025-04-01 122.600000\n",
      "2025-05-01 122.800000\n",
      "2025-06-01 122.300000\n",
      "2025-07-01 122.847488\n",
      "\n",
      "=== Best Parameters Found ===\n",
      "{'colsample_bytree': 1, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# === 1. SET PARAMETERS ===\n",
    "TARGET_COL = 'EMP'\n",
    "EXOG_COLS = ['WTI', 'Brent']\n",
    "df = pd.read_pickle(\"Production1.pkl\")  # Replace with your actual input file\n",
    "df = df[df['ds'] >= pd.to_datetime('2020-01-01')].reset_index(drop=True)\n",
    "\n",
    "# === 2. CLEAN DATA ===\n",
    "df['ds'] = pd.to_datetime(df['ds'], errors='coerce')\n",
    "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')\n",
    "for col in EXOG_COLS:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df = df.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "# === 3. FEATURE ENGINEERING ===\n",
    "df['month_num'] = df['ds'].dt.month\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
    "\n",
    "for lag in [1, 2, 3, 6]:\n",
    "    df[f'{TARGET_COL}_lag{lag}'] = df[TARGET_COL].shift(lag)\n",
    "    for col in EXOG_COLS:\n",
    "        df[f'{col.replace(\" \", \"\")}_lag{lag}'] = df[col].shift(lag)\n",
    "\n",
    "df[f'{TARGET_COL}_roll3'] = df[TARGET_COL].rolling(window=3).mean().shift(1)\n",
    "for col in EXOG_COLS:\n",
    "    df[f'{col.replace(\" \", \"\")}_roll3'] = df[col].rolling(window=3).mean().shift(1)\n",
    "\n",
    "# === 4. DEFINE FEATURES & TARGET ===\n",
    "features = (\n",
    "    EXOG_COLS +\n",
    "    ['month_num', 'month_sin', 'month_cos'] +\n",
    "    [f'{TARGET_COL}_lag{l}' for l in [1,2,3,6]] +\n",
    "    [f'{TARGET_COL}_roll3'] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag1' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag2' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_roll3' for col in EXOG_COLS]\n",
    ")\n",
    "\n",
    "df_hist = df.dropna(subset=[TARGET_COL] + features).copy()\n",
    "X_train = df_hist[features].apply(pd.to_numeric, errors='coerce')\n",
    "y_train = pd.to_numeric(df_hist[TARGET_COL], errors='coerce')\n",
    "\n",
    "valid_idx = X_train.dropna().index\n",
    "X_train = X_train.loc[valid_idx]\n",
    "y_train = y_train.loc[valid_idx]\n",
    "\n",
    "# === 5. TRUE HOLD-OUT BACKTEST (80% train, 20% test) ===\n",
    "df_backtest = df_hist.loc[valid_idx].copy()\n",
    "X_all = df_backtest[features]\n",
    "y_all = df_backtest[TARGET_COL]\n",
    "\n",
    "split_index = int(len(X_all) * 0.8)\n",
    "X_train_split, X_test = X_all.iloc[:split_index], X_all.iloc[split_index:]\n",
    "y_train_split, y_test = y_all.iloc[:split_index], y_all.iloc[split_index:]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=2,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_split, y_train_split, verbose=False)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "mape = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "\n",
    "print(\"\\n=== Hold-Out Backtest Error Metrics ===\")\n",
    "print(f\"MAE  (Mean Absolute Error):      {mae:.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
    "print(f\"MAPE (Mean Absolute % Error):   {mape:.2f}%\")\n",
    "\n",
    "# === 6. RE-TRAIN ON ALL DATA BEFORE FORECASTING ===\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# === 7. FORECAST MISSING TARGET VALUES ===\n",
    "missing_idxs = df.index[df[TARGET_COL].isna()]\n",
    "\n",
    "for i in missing_idxs:\n",
    "    prior = df.loc[:i - 1].copy()\n",
    "    last = prior.iloc[-1]\n",
    "\n",
    "    new_feats = {\n",
    "        'month_num': df.at[i, 'ds'].month,\n",
    "        'month_sin': np.sin(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        'month_cos': np.cos(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        f'{TARGET_COL}_lag1': last[TARGET_COL],\n",
    "        f'{TARGET_COL}_lag2': last[f'{TARGET_COL}_lag1'],\n",
    "        f'{TARGET_COL}_lag3': last[f'{TARGET_COL}_lag2'],\n",
    "        f'{TARGET_COL}_lag6': prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else last[TARGET_COL],\n",
    "        f'{TARGET_COL}_roll3': pd.to_numeric(prior[TARGET_COL].iloc[-3:], errors='coerce').mean(),\n",
    "    }\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        new_feats[col] = df.at[i, col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "    input_df = pd.DataFrame([new_feats])\n",
    "    input_df = input_df.reindex(columns=features).apply(pd.to_numeric, errors='coerce')\n",
    "    y_pred = model.predict(input_df)[0]\n",
    "\n",
    "    df.loc[i, TARGET_COL] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag1'] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag2'] = last[f'{TARGET_COL}_lag1']\n",
    "    df.loc[i, f'{TARGET_COL}_lag3'] = last[f'{TARGET_COL}_lag2']\n",
    "    df.loc[i, f'{TARGET_COL}_lag6'] = prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else y_pred\n",
    "\n",
    "    roll_vals = pd.concat([prior[TARGET_COL].iloc[-2:], pd.Series([y_pred])])\n",
    "    df.loc[i, f'{TARGET_COL}_roll3'] = roll_vals.mean() if len(roll_vals) == 3 else y_pred\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "# === 8. FINAL OUTPUT ===\n",
    "df = df[['ds', TARGET_COL]].copy()\n",
    "print(\"\\n=== Final df with historical + forecasted values ===\")\n",
    "print(df.tail(8).to_string(index=False))\n",
    "\n",
    "df_full = df\n",
    "\n",
    "#=============================#\n",
    "#    Optimize Parameters      #\n",
    "#=============================#\n",
    "\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# === 5A. HYPERPARAMETER TUNING ===\n",
    "# === HYPERPARAMETER SEARCH ONLY ===\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 600, 800],\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [1, 0.8, 0.6],\n",
    "    'colsample_bytree': [1, 0.8, 0.6]\n",
    "}\n",
    "\n",
    "grid_model = XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=grid_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n=== Best Parameters Found ===\")\n",
    "print(grid_search.best_params_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690dca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hold-Out Backtest Error Metrics ===\n",
      "MAE  (Mean Absolute Error):      1.73\n",
      "RMSE (Root Mean Squared Error): 2.76\n",
      "MAPE (Mean Absolute % Error):   1.74%\n",
      "\n",
      "=== Final df with historical + forecasted values ===\n",
      "        ds       IND\n",
      "2024-12-01 99.610300\n",
      "2025-01-01 98.571700\n",
      "2025-02-01 99.144600\n",
      "2025-03-01 99.993400\n",
      "2025-04-01 98.247200\n",
      "2025-05-01 95.689000\n",
      "2025-06-01 95.978699\n",
      "2025-07-01 95.821808\n",
      "\n",
      "=== Best Parameters Found ===\n",
      "{'colsample_bytree': 1, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 400, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# === 1. SET PARAMETERS ===\n",
    "TARGET_COL = 'IND'\n",
    "EXOG_COLS = ['WTI', 'Brent']\n",
    "df = pd.read_pickle(\"Production1.pkl\")  # Replace with your actual input file\n",
    "df = df[df['ds'] >= pd.to_datetime('2020-01-01')].reset_index(drop=True)\n",
    "\n",
    "# === 2. CLEAN DATA ===\n",
    "df['ds'] = pd.to_datetime(df['ds'], errors='coerce')\n",
    "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')\n",
    "for col in EXOG_COLS:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df = df.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "# === 3. FEATURE ENGINEERING ===\n",
    "df['month_num'] = df['ds'].dt.month\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
    "\n",
    "for lag in [1, 2, 3, 6]:\n",
    "    df[f'{TARGET_COL}_lag{lag}'] = df[TARGET_COL].shift(lag)\n",
    "    for col in EXOG_COLS:\n",
    "        df[f'{col.replace(\" \", \"\")}_lag{lag}'] = df[col].shift(lag)\n",
    "\n",
    "df[f'{TARGET_COL}_roll3'] = df[TARGET_COL].rolling(window=3).mean().shift(1)\n",
    "for col in EXOG_COLS:\n",
    "    df[f'{col.replace(\" \", \"\")}_roll3'] = df[col].rolling(window=3).mean().shift(1)\n",
    "\n",
    "# === 4. DEFINE FEATURES & TARGET ===\n",
    "features = (\n",
    "    EXOG_COLS +\n",
    "    ['month_num', 'month_sin', 'month_cos'] +\n",
    "    [f'{TARGET_COL}_lag{l}' for l in [1,2,3,6]] +\n",
    "    [f'{TARGET_COL}_roll3'] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag1' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag2' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_roll3' for col in EXOG_COLS]\n",
    ")\n",
    "\n",
    "df_hist = df.dropna(subset=[TARGET_COL] + features).copy()\n",
    "X_train = df_hist[features].apply(pd.to_numeric, errors='coerce')\n",
    "y_train = pd.to_numeric(df_hist[TARGET_COL], errors='coerce')\n",
    "\n",
    "valid_idx = X_train.dropna().index\n",
    "X_train = X_train.loc[valid_idx]\n",
    "y_train = y_train.loc[valid_idx]\n",
    "\n",
    "# === 5. TRUE HOLD-OUT BACKTEST (80% train, 20% test) ===\n",
    "df_backtest = df_hist.loc[valid_idx].copy()\n",
    "X_all = df_backtest[features]\n",
    "y_all = df_backtest[TARGET_COL]\n",
    "\n",
    "split_index = int(len(X_all) * 0.8)\n",
    "X_train_split, X_test = X_all.iloc[:split_index], X_all.iloc[split_index:]\n",
    "y_train_split, y_test = y_all.iloc[:split_index], y_all.iloc[split_index:]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=800,\n",
    "    max_depth=2,\n",
    "    learning_rate=0.05,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_split, y_train_split, verbose=False)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "mape = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "\n",
    "print(\"\\n=== Hold-Out Backtest Error Metrics ===\")\n",
    "print(f\"MAE  (Mean Absolute Error):      {mae:.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
    "print(f\"MAPE (Mean Absolute % Error):   {mape:.2f}%\")\n",
    "\n",
    "# === 6. RE-TRAIN ON ALL DATA BEFORE FORECASTING ===\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# === 7. FORECAST MISSING TARGET VALUES ===\n",
    "missing_idxs = df.index[df[TARGET_COL].isna()]\n",
    "\n",
    "for i in missing_idxs:\n",
    "    prior = df.loc[:i - 1].copy()\n",
    "    last = prior.iloc[-1]\n",
    "\n",
    "    new_feats = {\n",
    "        'month_num': df.at[i, 'ds'].month,\n",
    "        'month_sin': np.sin(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        'month_cos': np.cos(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        f'{TARGET_COL}_lag1': last[TARGET_COL],\n",
    "        f'{TARGET_COL}_lag2': last[f'{TARGET_COL}_lag1'],\n",
    "        f'{TARGET_COL}_lag3': last[f'{TARGET_COL}_lag2'],\n",
    "        f'{TARGET_COL}_lag6': prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else last[TARGET_COL],\n",
    "        f'{TARGET_COL}_roll3': pd.to_numeric(prior[TARGET_COL].iloc[-3:], errors='coerce').mean(),\n",
    "    }\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        new_feats[col] = df.at[i, col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "    input_df = pd.DataFrame([new_feats])\n",
    "    input_df = input_df.reindex(columns=features).apply(pd.to_numeric, errors='coerce')\n",
    "    y_pred = model.predict(input_df)[0]\n",
    "\n",
    "    df.loc[i, TARGET_COL] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag1'] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag2'] = last[f'{TARGET_COL}_lag1']\n",
    "    df.loc[i, f'{TARGET_COL}_lag3'] = last[f'{TARGET_COL}_lag2']\n",
    "    df.loc[i, f'{TARGET_COL}_lag6'] = prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else y_pred\n",
    "\n",
    "    roll_vals = pd.concat([prior[TARGET_COL].iloc[-2:], pd.Series([y_pred])])\n",
    "    df.loc[i, f'{TARGET_COL}_roll3'] = roll_vals.mean() if len(roll_vals) == 3 else y_pred\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "# === 8. FINAL OUTPUT ===\n",
    "df = df[['ds', TARGET_COL]].copy()\n",
    "print(\"\\n=== Final df with historical + forecasted values ===\")\n",
    "print(df.tail(8).to_string(index=False))\n",
    "\n",
    "if TARGET_COL not in df_full.columns:\n",
    "    df_full = pd.merge(df_full, df, on='ds', how='outer')\n",
    "else:\n",
    "    df_full.set_index('ds', inplace=True)\n",
    "    df.set_index('ds', inplace=True)\n",
    "    df_full.update(df[[TARGET_COL]])\n",
    "    df_full.reset_index(inplace=True)\n",
    "\n",
    "#=============================#\n",
    "#    Optimize Parameters      #\n",
    "#=============================#\n",
    "\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# === 5A. HYPERPARAMETER TUNING ===\n",
    "# === HYPERPARAMETER SEARCH ONLY ===\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 600, 800],\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [1, 0.8, 0.6],\n",
    "    'colsample_bytree': [1, 0.8, 0.6]\n",
    "}\n",
    "\n",
    "grid_model = XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=grid_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n=== Best Parameters Found ===\")\n",
    "print(grid_search.best_params_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c83aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hold-Out Backtest Error Metrics ===\n",
      "MAE  (Mean Absolute Error):      13.13\n",
      "RMSE (Root Mean Squared Error): 14.01\n",
      "MAPE (Mean Absolute % Error):   2.75%\n",
      "\n",
      "=== Final df with historical + forecasted values ===\n",
      "        ds       Rigs\n",
      "2024-12-01 483.000000\n",
      "2025-01-01 478.000000\n",
      "2025-02-01 484.000000\n",
      "2025-03-01 486.000000\n",
      "2025-04-01 475.000000\n",
      "2025-05-01 462.000000\n",
      "2025-06-01 469.271057\n",
      "2025-07-01 474.377747\n",
      "\n",
      "=== Best Parameters Found ===\n",
      "{'colsample_bytree': 1, 'learning_rate': 0.05, 'max_depth': 8, 'n_estimators': 600, 'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "# === 1. SET PARAMETERS ===\n",
    "TARGET_COL = 'Rigs'\n",
    "EXOG_COLS = ['WTI', 'Brent']\n",
    "df = pd.read_pickle(\"Production1.pkl\")  # Replace with your actual input file\n",
    "df = df[df['ds'] >= pd.to_datetime('2020-01-01')].reset_index(drop=True)\n",
    "\n",
    "# === 2. CLEAN DATA ===\n",
    "df['ds'] = pd.to_datetime(df['ds'], errors='coerce')\n",
    "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')\n",
    "for col in EXOG_COLS:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df = df.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "# === 3. FEATURE ENGINEERING ===\n",
    "df['month_num'] = df['ds'].dt.month\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
    "\n",
    "for lag in [1, 2, 3, 6]:\n",
    "    df[f'{TARGET_COL}_lag{lag}'] = df[TARGET_COL].shift(lag)\n",
    "    for col in EXOG_COLS:\n",
    "        df[f'{col.replace(\" \", \"\")}_lag{lag}'] = df[col].shift(lag)\n",
    "\n",
    "df[f'{TARGET_COL}_roll3'] = df[TARGET_COL].rolling(window=3).mean().shift(1)\n",
    "for col in EXOG_COLS:\n",
    "    df[f'{col.replace(\" \", \"\")}_roll3'] = df[col].rolling(window=3).mean().shift(1)\n",
    "\n",
    "# === 4. DEFINE FEATURES & TARGET ===\n",
    "features = (\n",
    "    EXOG_COLS +\n",
    "    ['month_num', 'month_sin', 'month_cos'] +\n",
    "    [f'{TARGET_COL}_lag{l}' for l in [1,2,3,6]] +\n",
    "    [f'{TARGET_COL}_roll3'] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag1' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag2' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_roll3' for col in EXOG_COLS]\n",
    ")\n",
    "\n",
    "df_hist = df.dropna(subset=[TARGET_COL] + features).copy()\n",
    "X_train = df_hist[features].apply(pd.to_numeric, errors='coerce')\n",
    "y_train = pd.to_numeric(df_hist[TARGET_COL], errors='coerce')\n",
    "\n",
    "valid_idx = X_train.dropna().index\n",
    "X_train = X_train.loc[valid_idx]\n",
    "y_train = y_train.loc[valid_idx]\n",
    "\n",
    "# === 5. TRUE HOLD-OUT BACKTEST (80% train, 20% test) ===\n",
    "df_backtest = df_hist.loc[valid_idx].copy()\n",
    "X_all = df_backtest[features]\n",
    "y_all = df_backtest[TARGET_COL]\n",
    "\n",
    "split_index = int(len(X_all) * 0.8)\n",
    "X_train_split, X_test = X_all.iloc[:split_index], X_all.iloc[split_index:]\n",
    "y_train_split, y_test = y_all.iloc[:split_index], y_all.iloc[split_index:]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.2,\n",
    "    subsample=1,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_split, y_train_split, verbose=False)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "mape = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "\n",
    "print(\"\\n=== Hold-Out Backtest Error Metrics ===\")\n",
    "print(f\"MAE  (Mean Absolute Error):      {mae:.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
    "print(f\"MAPE (Mean Absolute % Error):   {mape:.2f}%\")\n",
    "\n",
    "# === 6. RE-TRAIN ON ALL DATA BEFORE FORECASTING ===\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# === 7. FORECAST MISSING TARGET VALUES ===\n",
    "missing_idxs = df.index[df[TARGET_COL].isna()]\n",
    "\n",
    "for i in missing_idxs:\n",
    "    prior = df.loc[:i - 1].copy()\n",
    "    last = prior.iloc[-1]\n",
    "\n",
    "    new_feats = {\n",
    "        'month_num': df.at[i, 'ds'].month,\n",
    "        'month_sin': np.sin(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        'month_cos': np.cos(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        f'{TARGET_COL}_lag1': last[TARGET_COL],\n",
    "        f'{TARGET_COL}_lag2': last[f'{TARGET_COL}_lag1'],\n",
    "        f'{TARGET_COL}_lag3': last[f'{TARGET_COL}_lag2'],\n",
    "        f'{TARGET_COL}_lag6': prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else last[TARGET_COL],\n",
    "        f'{TARGET_COL}_roll3': pd.to_numeric(prior[TARGET_COL].iloc[-3:], errors='coerce').mean(),\n",
    "    }\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        new_feats[col] = df.at[i, col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "    input_df = pd.DataFrame([new_feats])\n",
    "    input_df = input_df.reindex(columns=features).apply(pd.to_numeric, errors='coerce')\n",
    "    y_pred = model.predict(input_df)[0]\n",
    "\n",
    "    df.loc[i, TARGET_COL] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag1'] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag2'] = last[f'{TARGET_COL}_lag1']\n",
    "    df.loc[i, f'{TARGET_COL}_lag3'] = last[f'{TARGET_COL}_lag2']\n",
    "    df.loc[i, f'{TARGET_COL}_lag6'] = prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else y_pred\n",
    "\n",
    "    roll_vals = pd.concat([prior[TARGET_COL].iloc[-2:], pd.Series([y_pred])])\n",
    "    df.loc[i, f'{TARGET_COL}_roll3'] = roll_vals.mean() if len(roll_vals) == 3 else y_pred\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "# === 8. FINAL OUTPUT ===\n",
    "df = df[['ds', TARGET_COL]].copy()\n",
    "print(\"\\n=== Final df with historical + forecasted values ===\")\n",
    "print(df.tail(8).to_string(index=False))\n",
    "\n",
    "if TARGET_COL not in df_full.columns:\n",
    "    df_full = pd.merge(df_full, df, on='ds', how='outer')\n",
    "else:\n",
    "    df_full.set_index('ds', inplace=True)\n",
    "    df.set_index('ds', inplace=True)\n",
    "    df_full.update(df[[TARGET_COL]])\n",
    "    df_full.reset_index(inplace=True)\n",
    "\n",
    "#=============================#\n",
    "#    Optimize Parameters      #\n",
    "#=============================#\n",
    "\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# === 5A. HYPERPARAMETER TUNING ===\n",
    "# === HYPERPARAMETER SEARCH ONLY ===\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 600, 800],\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [1, 0.8, 0.6],\n",
    "    'colsample_bytree': [1, 0.8, 0.6]\n",
    "}\n",
    "\n",
    "grid_model = XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=grid_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n=== Best Parameters Found ===\")\n",
    "print(grid_search.best_params_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hold-Out Backtest Error Metrics ===\n",
      "MAE  (Mean Absolute Error):      60.38\n",
      "RMSE (Root Mean Squared Error): 73.19\n",
      "MAPE (Mean Absolute % Error):   7.29%\n",
      "\n",
      "=== Final df with historical + forecasted values ===\n",
      "        ds      Wells\n",
      "2024-12-01 765.000000\n",
      "2025-01-01 758.000000\n",
      "2025-02-01 769.000000\n",
      "2025-03-01 771.000000\n",
      "2025-04-01 770.000000\n",
      "2025-05-01 745.000000\n",
      "2025-06-01 742.341309\n",
      "2025-07-01 785.383484\n",
      "\n",
      "=== Best Parameters Found ===\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# === 1. SET PARAMETERS ===\n",
    "TARGET_COL = 'Wells'\n",
    "EXOG_COLS = ['WTI', 'Brent']\n",
    "df = pd.read_pickle(\"Production1.pkl\")  # Replace with your actual input file\n",
    "df = df[df['ds'] >= pd.to_datetime('2020-01-01')].reset_index(drop=True)\n",
    "\n",
    "# === 2. CLEAN DATA ===\n",
    "df['ds'] = pd.to_datetime(df['ds'], errors='coerce')\n",
    "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')\n",
    "for col in EXOG_COLS:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df = df.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "# === 3. FEATURE ENGINEERING ===\n",
    "df['month_num'] = df['ds'].dt.month\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
    "\n",
    "for lag in [1, 2, 3, 6]:\n",
    "    df[f'{TARGET_COL}_lag{lag}'] = df[TARGET_COL].shift(lag)\n",
    "    for col in EXOG_COLS:\n",
    "        df[f'{col.replace(\" \", \"\")}_lag{lag}'] = df[col].shift(lag)\n",
    "\n",
    "df[f'{TARGET_COL}_roll3'] = df[TARGET_COL].rolling(window=3).mean().shift(1)\n",
    "for col in EXOG_COLS:\n",
    "    df[f'{col.replace(\" \", \"\")}_roll3'] = df[col].rolling(window=3).mean().shift(1)\n",
    "\n",
    "# === 4. DEFINE FEATURES & TARGET ===\n",
    "features = (\n",
    "    EXOG_COLS +\n",
    "    ['month_num', 'month_sin', 'month_cos'] +\n",
    "    [f'{TARGET_COL}_lag{l}' for l in [1,2,3,6]] +\n",
    "    [f'{TARGET_COL}_roll3'] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag1' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag2' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_roll3' for col in EXOG_COLS]\n",
    ")\n",
    "\n",
    "df_hist = df.dropna(subset=[TARGET_COL] + features).copy()\n",
    "X_train = df_hist[features].apply(pd.to_numeric, errors='coerce')\n",
    "y_train = pd.to_numeric(df_hist[TARGET_COL], errors='coerce')\n",
    "\n",
    "valid_idx = X_train.dropna().index\n",
    "X_train = X_train.loc[valid_idx]\n",
    "y_train = y_train.loc[valid_idx]\n",
    "\n",
    "# === 5. TRUE HOLD-OUT BACKTEST (80% train, 20% test) ===\n",
    "df_backtest = df_hist.loc[valid_idx].copy()\n",
    "X_all = df_backtest[features]\n",
    "y_all = df_backtest[TARGET_COL]\n",
    "\n",
    "split_index = int(len(X_all) * 0.8)\n",
    "X_train_split, X_test = X_all.iloc[:split_index], X_all.iloc[split_index:]\n",
    "y_train_split, y_test = y_all.iloc[:split_index], y_all.iloc[split_index:]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.2,\n",
    "    subsample=1,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_split, y_train_split, verbose=False)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "mape = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "\n",
    "print(\"\\n=== Hold-Out Backtest Error Metrics ===\")\n",
    "print(f\"MAE  (Mean Absolute Error):      {mae:.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
    "print(f\"MAPE (Mean Absolute % Error):   {mape:.2f}%\")\n",
    "\n",
    "# === 6. RE-TRAIN ON ALL DATA BEFORE FORECASTING ===\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# === 7. FORECAST MISSING TARGET VALUES ===\n",
    "missing_idxs = df.index[df[TARGET_COL].isna()]\n",
    "\n",
    "for i in missing_idxs:\n",
    "    prior = df.loc[:i - 1].copy()\n",
    "    last = prior.iloc[-1]\n",
    "\n",
    "    new_feats = {\n",
    "        'month_num': df.at[i, 'ds'].month,\n",
    "        'month_sin': np.sin(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        'month_cos': np.cos(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        f'{TARGET_COL}_lag1': last[TARGET_COL],\n",
    "        f'{TARGET_COL}_lag2': last[f'{TARGET_COL}_lag1'],\n",
    "        f'{TARGET_COL}_lag3': last[f'{TARGET_COL}_lag2'],\n",
    "        f'{TARGET_COL}_lag6': prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else last[TARGET_COL],\n",
    "        f'{TARGET_COL}_roll3': pd.to_numeric(prior[TARGET_COL].iloc[-3:], errors='coerce').mean(),\n",
    "    }\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        new_feats[col] = df.at[i, col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "    input_df = pd.DataFrame([new_feats])\n",
    "    input_df = input_df.reindex(columns=features).apply(pd.to_numeric, errors='coerce')\n",
    "    y_pred = model.predict(input_df)[0]\n",
    "\n",
    "    df.loc[i, TARGET_COL] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag1'] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag2'] = last[f'{TARGET_COL}_lag1']\n",
    "    df.loc[i, f'{TARGET_COL}_lag3'] = last[f'{TARGET_COL}_lag2']\n",
    "    df.loc[i, f'{TARGET_COL}_lag6'] = prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else y_pred\n",
    "\n",
    "    roll_vals = pd.concat([prior[TARGET_COL].iloc[-2:], pd.Series([y_pred])])\n",
    "    df.loc[i, f'{TARGET_COL}_roll3'] = roll_vals.mean() if len(roll_vals) == 3 else y_pred\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "# === 8. FINAL OUTPUT ===\n",
    "df = df[['ds', TARGET_COL]].copy()\n",
    "print(\"\\n=== Final df with historical + forecasted values ===\")\n",
    "print(df.tail(8).to_string(index=False))\n",
    "\n",
    "if TARGET_COL not in df_full.columns:\n",
    "    df_full = pd.merge(df_full, df, on='ds', how='outer')\n",
    "else:\n",
    "    df_full.set_index('ds', inplace=True)\n",
    "    df.set_index('ds', inplace=True)\n",
    "    df_full.update(df[[TARGET_COL]])\n",
    "    df_full.reset_index(inplace=True)\n",
    "\n",
    "#=============================#\n",
    "#    Optimize Parameters      #\n",
    "#=============================#\n",
    "\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# === 5A. HYPERPARAMETER TUNING ===\n",
    "# === HYPERPARAMETER SEARCH ONLY ===\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 600, 800],\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [1, 0.8, 0.6],\n",
    "    'colsample_bytree': [1, 0.8, 0.6]\n",
    "}\n",
    "\n",
    "grid_model = XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=grid_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n=== Best Parameters Found ===\")\n",
    "print(grid_search.best_params_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22396c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hold-Out Backtest Error Metrics ===\n",
      "MAE  (Mean Absolute Error):      8.90\n",
      "RMSE (Root Mean Squared Error): 9.50\n",
      "MAPE (Mean Absolute % Error):   2.09%\n",
      "\n",
      "=== Final df with historical + forecasted values ===\n",
      "        ds      Store\n",
      "2024-12-01 413.734000\n",
      "2025-01-01 418.782000\n",
      "2025-02-01 429.786000\n",
      "2025-03-01 431.688000\n",
      "2025-04-01 438.666000\n",
      "2025-05-01 435.018000\n",
      "2025-06-01 433.022461\n",
      "2025-07-01 430.937286\n",
      "\n",
      "=== Best Parameters Found ===\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# === 1. SET PARAMETERS ===\n",
    "TARGET_COL = 'Store'\n",
    "EXOG_COLS = ['WTI', 'Brent']\n",
    "df = pd.read_pickle(\"Production1.pkl\")  # Replace with your actual input file\n",
    "df = df[df['ds'] >= pd.to_datetime('2020-01-01')].reset_index(drop=True)\n",
    "\n",
    "# === 2. CLEAN DATA ===\n",
    "df['ds'] = pd.to_datetime(df['ds'], errors='coerce')\n",
    "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')\n",
    "for col in EXOG_COLS:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df = df.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "# === 3. FEATURE ENGINEERING ===\n",
    "df['month_num'] = df['ds'].dt.month\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
    "\n",
    "for lag in [1, 2, 3, 6]:\n",
    "    df[f'{TARGET_COL}_lag{lag}'] = df[TARGET_COL].shift(lag)\n",
    "    for col in EXOG_COLS:\n",
    "        df[f'{col.replace(\" \", \"\")}_lag{lag}'] = df[col].shift(lag)\n",
    "\n",
    "df[f'{TARGET_COL}_roll3'] = df[TARGET_COL].rolling(window=3).mean().shift(1)\n",
    "for col in EXOG_COLS:\n",
    "    df[f'{col.replace(\" \", \"\")}_roll3'] = df[col].rolling(window=3).mean().shift(1)\n",
    "\n",
    "# === 4. DEFINE FEATURES & TARGET ===\n",
    "features = (\n",
    "    EXOG_COLS +\n",
    "    ['month_num', 'month_sin', 'month_cos'] +\n",
    "    [f'{TARGET_COL}_lag{l}' for l in [1,2,3,6]] +\n",
    "    [f'{TARGET_COL}_roll3'] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag1' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag2' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_roll3' for col in EXOG_COLS]\n",
    ")\n",
    "\n",
    "df_hist = df.dropna(subset=[TARGET_COL] + features).copy()\n",
    "X_train = df_hist[features].apply(pd.to_numeric, errors='coerce')\n",
    "y_train = pd.to_numeric(df_hist[TARGET_COL], errors='coerce')\n",
    "\n",
    "valid_idx = X_train.dropna().index\n",
    "X_train = X_train.loc[valid_idx]\n",
    "y_train = y_train.loc[valid_idx]\n",
    "\n",
    "# === 5. TRUE HOLD-OUT BACKTEST (80% train, 20% test) ===\n",
    "df_backtest = df_hist.loc[valid_idx].copy()\n",
    "X_all = df_backtest[features]\n",
    "y_all = df_backtest[TARGET_COL]\n",
    "\n",
    "split_index = int(len(X_all) * 0.8)\n",
    "X_train_split, X_test = X_all.iloc[:split_index], X_all.iloc[split_index:]\n",
    "y_train_split, y_test = y_all.iloc[:split_index], y_all.iloc[split_index:]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=2,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_split, y_train_split, verbose=False)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "mape = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "\n",
    "print(\"\\n=== Hold-Out Backtest Error Metrics ===\")\n",
    "print(f\"MAE  (Mean Absolute Error):      {mae:.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
    "print(f\"MAPE (Mean Absolute % Error):   {mape:.2f}%\")\n",
    "\n",
    "# === 6. RE-TRAIN ON ALL DATA BEFORE FORECASTING ===\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "# === 7. FORECAST MISSING TARGET VALUES ===\n",
    "missing_idxs = df.index[df[TARGET_COL].isna()]\n",
    "\n",
    "for i in missing_idxs:\n",
    "    prior = df.loc[:i - 1].copy()\n",
    "    last = prior.iloc[-1]\n",
    "\n",
    "    new_feats = {\n",
    "        'month_num': df.at[i, 'ds'].month,\n",
    "        'month_sin': np.sin(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        'month_cos': np.cos(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        f'{TARGET_COL}_lag1': last[TARGET_COL],\n",
    "        f'{TARGET_COL}_lag2': last[f'{TARGET_COL}_lag1'],\n",
    "        f'{TARGET_COL}_lag3': last[f'{TARGET_COL}_lag2'],\n",
    "        f'{TARGET_COL}_lag6': prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else last[TARGET_COL],\n",
    "        f'{TARGET_COL}_roll3': pd.to_numeric(prior[TARGET_COL].iloc[-3:], errors='coerce').mean(),\n",
    "    }\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        new_feats[col] = df.at[i, col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "    input_df = pd.DataFrame([new_feats])\n",
    "    input_df = input_df.reindex(columns=features).apply(pd.to_numeric, errors='coerce')\n",
    "    y_pred = model.predict(input_df)[0]\n",
    "\n",
    "    df.loc[i, TARGET_COL] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag1'] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag2'] = last[f'{TARGET_COL}_lag1']\n",
    "    df.loc[i, f'{TARGET_COL}_lag3'] = last[f'{TARGET_COL}_lag2']\n",
    "    df.loc[i, f'{TARGET_COL}_lag6'] = prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else y_pred\n",
    "\n",
    "    roll_vals = pd.concat([prior[TARGET_COL].iloc[-2:], pd.Series([y_pred])])\n",
    "    df.loc[i, f'{TARGET_COL}_roll3'] = roll_vals.mean() if len(roll_vals) == 3 else y_pred\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "# === 8. FINAL OUTPUT ===\n",
    "df = df[['ds', TARGET_COL]].copy()\n",
    "df.to_pickle(\"Storage.pkl\")\n",
    "print(\"\\n=== Final df with historical + forecasted values ===\")\n",
    "print(df.tail(8).to_string(index=False))\n",
    "\n",
    "if TARGET_COL not in df_full.columns:\n",
    "    df_full = pd.merge(df_full, df, on='ds', how='outer')\n",
    "else:\n",
    "    df_full.set_index('ds', inplace=True)\n",
    "    df.set_index('ds', inplace=True)\n",
    "    df_full.update(df[[TARGET_COL]])\n",
    "    df_full.reset_index(inplace=True)\n",
    "\n",
    "#=============================#\n",
    "#    Optimize Parameters      #\n",
    "#=============================#\n",
    "\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# === 5A. HYPERPARAMETER TUNING ===\n",
    "# === HYPERPARAMETER SEARCH ONLY ===\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 600, 800],\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [1, 0.8, 0.6],\n",
    "    'colsample_bytree': [1, 0.8, 0.6]\n",
    "}\n",
    "\n",
    "grid_model = XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=grid_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n=== Best Parameters Found ===\")\n",
    "print(grid_search.best_params_)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f94a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ds        IND         EMP       Store        Rigs       Wells  \\\n",
      "639 2025-04-01  98.247200  122.600000  438.666000  475.000000  770.000000   \n",
      "640 2025-05-01  95.689000  122.800000  435.018000  462.000000  745.000000   \n",
      "641 2025-06-01  95.978699  122.300000  433.022461  469.271057  742.341309   \n",
      "642 2025-07-01  95.821808  122.847488  430.937286  474.377747  785.383484   \n",
      "643 2025-08-01        NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "          Prod  \n",
      "639  14107.833  \n",
      "640        NaN  \n",
      "641        NaN  \n",
      "642        NaN  \n",
      "643        NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1v/qxw436v577vd4tnnpxrghrpw0000gn/T/ipykernel_63499/3736537903.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_full = pd.concat([df_full, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"Production1.pkl\")\n",
    "df = df[['ds', 'Prod']].copy()\n",
    "\n",
    "if 'Prod' not in df_full.columns:\n",
    "    df_full = pd.merge(df_full, df, on='ds', how='outer')\n",
    "else:\n",
    "    df_full.set_index('ds', inplace=True)\n",
    "    df.set_index('ds', inplace=True)\n",
    "    df_full.update(df[['Prod']])\n",
    "    df_full.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "df_full = df_full[['ds', 'IND', 'EMP', 'Store', 'Rigs', 'Wells', 'Prod']].copy()\n",
    "\n",
    "\n",
    "# Check if last row (excluding 'ds') is all NaN\n",
    "if not df_full.iloc[-1].drop(labels='ds').isna().all():\n",
    "    next_date = df_full['ds'].max() + relativedelta(months=1)\n",
    "    new_row = {col: pd.NA for col in df_full.columns}\n",
    "    new_row['ds'] = next_date\n",
    "    df_full = pd.concat([df_full, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "print(df_full.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0bc579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hold-Out Backtest Error Metrics ===\n",
      "MAE  (Mean Absolute Error):      452.18\n",
      "RMSE (Root Mean Squared Error): 547.16\n",
      "MAPE (Mean Absolute % Error):   3.20%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final df with historical + forecasted values ===\n",
      "        ds         Prod\n",
      "2025-01-01 13229.518000\n",
      "2025-02-01 14008.885000\n",
      "2025-03-01 14261.269000\n",
      "2025-04-01 14107.833000\n",
      "2025-05-01 14083.351562\n",
      "2025-06-01 14138.632812\n",
      "2025-07-01 13685.968750\n",
      "2025-08-01 13886.073242\n",
      "\n",
      "=== Best Parameters Found ===\n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === 1. SET PARAMETERS ===\n",
    "TARGET_COL = 'Prod'\n",
    "EXOG_COLS = ['IND', 'EMP', 'Store', 'Rigs', 'Wells']\n",
    "df = df_full  # Replace with your actual input file\n",
    "df = df[df['ds'] >= pd.to_datetime('2020-01-01')].reset_index(drop=True)\n",
    "\n",
    "# === 2. CLEAN DATA ===\n",
    "df['ds'] = pd.to_datetime(df['ds'], errors='coerce')\n",
    "df[TARGET_COL] = pd.to_numeric(df[TARGET_COL], errors='coerce')\n",
    "for col in EXOG_COLS:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df = df.sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "# === 3. FEATURE ENGINEERING ===\n",
    "df['month_num'] = df['ds'].dt.month\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
    "\n",
    "for lag in [1, 2, 3, 6]:\n",
    "    df[f'{TARGET_COL}_lag{lag}'] = df[TARGET_COL].shift(lag)\n",
    "    for col in EXOG_COLS:\n",
    "        df[f'{col.replace(\" \", \"\")}_lag{lag}'] = df[col].shift(lag)\n",
    "\n",
    "df[f'{TARGET_COL}_roll3'] = df[TARGET_COL].rolling(window=3).mean().shift(1)\n",
    "for col in EXOG_COLS:\n",
    "    df[f'{col.replace(\" \", \"\")}_roll3'] = df[col].rolling(window=3).mean().shift(1)\n",
    "\n",
    "# === 4. DEFINE FEATURES & TARGET ===\n",
    "features = (\n",
    "    EXOG_COLS +\n",
    "    ['month_num', 'month_sin', 'month_cos'] +\n",
    "    [f'{TARGET_COL}_lag{l}' for l in [1,2,3,6]] +\n",
    "    [f'{TARGET_COL}_roll3'] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag1' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_lag2' for col in EXOG_COLS] +\n",
    "    [f'{col.replace(\" \", \"\")}_roll3' for col in EXOG_COLS]\n",
    ")\n",
    "\n",
    "df_hist = df.dropna(subset=[TARGET_COL] + features).copy()\n",
    "X_train = df_hist[features].apply(pd.to_numeric, errors='coerce')\n",
    "y_train = pd.to_numeric(df_hist[TARGET_COL], errors='coerce')\n",
    "\n",
    "valid_idx = X_train.dropna().index\n",
    "X_train = X_train.loc[valid_idx]\n",
    "y_train = y_train.loc[valid_idx]\n",
    "\n",
    "# === 5. TRUE HOLD-OUT BACKTEST (80% train, 20% test) ===\n",
    "df_backtest = df_hist.loc[valid_idx].copy()\n",
    "X_all = df_backtest[features]\n",
    "y_all = df_backtest[TARGET_COL]\n",
    "\n",
    "split_index = int(len(X_all) * 0.8)\n",
    "X_train_split, X_test = X_all.iloc[:split_index], X_all.iloc[split_index:]\n",
    "y_train_split, y_test = y_all.iloc[:split_index], y_all.iloc[split_index:]\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=2,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_split, y_train_split, verbose=False)\n",
    "\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "mape = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "\n",
    "print(\"\\n=== Hold-Out Backtest Error Metrics ===\")\n",
    "print(f\"MAE  (Mean Absolute Error):      {mae:.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
    "print(f\"MAPE (Mean Absolute % Error):   {mape:.2f}%\")\n",
    "\n",
    "# === 6. RE-TRAIN ON ALL DATA BEFORE FORECASTING ===\n",
    "model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "#\n",
    "\n",
    "importances = model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "top_n = 15\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(top_n), importances[sorted_idx][:top_n][::-1])\n",
    "plt.yticks(range(top_n), [feature_names[i] for i in sorted_idx[:top_n]][::-1])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === 7. FORECAST MISSING TARGET VALUES ===\n",
    "missing_idxs = df.index[df[TARGET_COL].isna()]\n",
    "\n",
    "for i in missing_idxs:\n",
    "    if i == 0:\n",
    "        continue  # Skip the first row since there's no prior data\n",
    "\n",
    "    prior = df.loc[:i - 1].copy()\n",
    "    if prior.empty:\n",
    "        continue  # Avoid crashing if prior is unexpectedly empty\n",
    "\n",
    "    last = prior.iloc[-1]\n",
    "\n",
    "    new_feats = {\n",
    "        'month_num': df.at[i, 'ds'].month,\n",
    "        'month_sin': np.sin(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        'month_cos': np.cos(2 * np.pi * df.at[i, 'ds'].month / 12),\n",
    "        f'{TARGET_COL}_lag1': last[TARGET_COL],\n",
    "        f'{TARGET_COL}_lag2': last[f'{TARGET_COL}_lag1'],\n",
    "        f'{TARGET_COL}_lag3': last[f'{TARGET_COL}_lag2'],\n",
    "        f'{TARGET_COL}_lag6': prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else last[TARGET_COL],\n",
    "        f'{TARGET_COL}_roll3': pd.to_numeric(prior[TARGET_COL].iloc[-3:], errors='coerce').mean(),\n",
    "    }\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        new_feats[col] = df.at[i, col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        new_feats[f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "    input_df = pd.DataFrame([new_feats])\n",
    "    input_df = input_df.reindex(columns=features).apply(pd.to_numeric, errors='coerce')\n",
    "    y_pred = model.predict(input_df)[0]\n",
    "\n",
    "    df.loc[i, TARGET_COL] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag1'] = y_pred\n",
    "    df.loc[i, f'{TARGET_COL}_lag2'] = last[f'{TARGET_COL}_lag1']\n",
    "    df.loc[i, f'{TARGET_COL}_lag3'] = last[f'{TARGET_COL}_lag2']\n",
    "    df.loc[i, f'{TARGET_COL}_lag6'] = prior[TARGET_COL].iloc[-6] if len(prior) >= 6 else y_pred\n",
    "\n",
    "    roll_vals = pd.concat([prior[TARGET_COL].iloc[-2:], pd.Series([y_pred])])\n",
    "    df.loc[i, f'{TARGET_COL}_roll3'] = roll_vals.mean() if len(roll_vals) == 3 else y_pred\n",
    "\n",
    "    for col in EXOG_COLS:\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag1'] = last[col]\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_lag2'] = last[f'{col.replace(\" \", \"\")}_lag1']\n",
    "        df.loc[i, f'{col.replace(\" \", \"\")}_roll3'] = pd.to_numeric(prior[col].iloc[-3:], errors='coerce').mean()\n",
    "\n",
    "# === 8. FINAL OUTPUT ===\n",
    "df = df[['ds', TARGET_COL]].copy()\n",
    "df.to_pickle(\"ProductionS.pkl\")\n",
    "print(\"\\n=== Final df with historical + forecasted values ===\")\n",
    "print(df.tail(8).to_string(index=False))\n",
    "\n",
    "\n",
    "#=============================#\n",
    "#    Optimize Parameters      #\n",
    "#=============================#\n",
    "\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# === 5A. HYPERPARAMETER TUNING ===\n",
    "# === HYPERPARAMETER SEARCH ONLY ===\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 600, 800],\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [1, 0.8, 0.6],\n",
    "    'colsample_bytree': [1, 0.8, 0.6]\n",
    "}\n",
    "\n",
    "grid_model = XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=grid_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n=== Best Parameters Found ===\")\n",
    "print(grid_search.best_params_)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf-env-64",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
